# 한국어 LLM 벤치마크 평가 리포트

## TL;DR

```
┌─────────────────────────────────────────────────────────────────────────┐
│  GPT-5.2       ████████████████████████████████████████  1위 (종합 최강)  │
│  Helpy-Pro     ██████████████████████████████░░░░░░░░░░  2위 (논리력 강점) │
│  GPT-OSS-20B   █████████████████████████████░░░░░░░░░░░  3위 (수학 특화)  │
└─────────────────────────────────────────────────────────────────────────┘
```

| 모델 | KoBEST | KMMLU | HAE-RAE | LogicKor | 1위 횟수 |
|------|:------:|:-----:|:-------:|:--------:|:--------:|
| **GPT-5.2** | **93.5%** | **77.4%** | **70.5%** | **4.77/5** | **4/4** |
| Helpy-Pro | 85.8% | 55.0% | 29.2% | 4.10/5 | 0/4 |
| GPT-OSS-20B | 84.9% | 65.9% | 57.9% | 3.52/5 | 0/4 |

**핵심 인사이트**:
- **GPT-5.2**가 모든 벤치마크에서 1위 달성
- **Helpy-Pro**는 논리적 사고력(LogicKor 4.10)에서 GPT-OSS-20B를 크게 앞섬
- **GPT-OSS-20B**는 수학(97.8%)에서 특출난 성능, 비용 대비 효율 최고

---

## 1. 평가 개요

### 1.1 평가 대상 모델

| 모델 | 유형 | 특징 |
|------|------|------|
| **GPT-5.2** | 상용 API | OpenAI 최신 모델 |
| **GPT-OSS-20B** | 오픈소스 | 20B 파라미터, 추론 특화 |
| **Helpy-Pro** | 한국어 특화 | 교육/상담 목적 최적화 |

### 1.2 평가 벤치마크

| 벤치마크 | 평가 영역 | 태스크 수 | 샘플 수 |
|----------|----------|:---------:|:-------:|
| **KoBEST** | 한국어 기초 이해 | 5 | 200/태스크 |
| **KMMLU** | 전문 지식 | 31 | 200/카테고리 |
| **HAE-RAE** | 한국어 고유성 | 13 | 전체 |
| **LogicKor** | 논리적 사고 | 1 | 42 |

### 1.3 평가 환경

- **평가 기간**: 2026-01-15 ~ 2026-01-21
- **API**: mlapi.run (OpenAI 호환)
- **샘플링**: 태스크당 최대 200개 (무작위)
- **채점**: 정규식 기반 정답 추출 + LLM Judge (LogicKor)

---

## 2. KoBEST 결과

> **한국어 기초 언어 이해 능력 평가**

### 2.1 태스크별 성능

| Task | GPT-5.2 | GPT-OSS-20B | Helpy-Pro | 평가 내용 |
|------|:-------:|:-----------:|:---------:|----------|
| BoolQ | - | - | **100.0%** | 예/아니오 질문 답변 |
| COPA | **96.6%** | 94.5% | 96.5% | 인과관계 추론 |
| HellaSwag | **94.5%** | 74.8% | 68.8% | 상식 기반 문장 완성 |
| WiC | **89.4%** | 85.3% | 78.0% | 문맥별 단어 의미 |
| **평균** | **93.5%** | 84.9% | 85.8% | |

### 2.2 성능 시각화

```
BoolQ      Helpy-Pro  ████████████████████ 100.0%
           GPT-5.2    (평가 없음)
           GPT-OSS    (평가 없음)

COPA       GPT-5.2    ███████████████████▌ 96.6%
           Helpy-Pro  ███████████████████▍ 96.5%
           GPT-OSS    ██████████████████▉  94.5%

HellaSwag  GPT-5.2    ██████████████████▉  94.5%
           GPT-OSS    ██████████████▉░░░░░ 74.8%
           Helpy-Pro  █████████████▊░░░░░░ 68.8%

WiC        GPT-5.2    █████████████████▉   89.4%
           GPT-OSS    █████████████████░░░ 85.3%
           Helpy-Pro  ███████████████▌░░░░ 78.0%
```

### 2.3 분석

- **GPT-5.2**: HellaSwag(94.5%)에서 다른 모델 대비 20%p 이상 우위
- **Helpy-Pro**: COPA에서 GPT-5.2와 거의 동등(96.5% vs 96.6%)
- **GPT-OSS-20B**: 전반적으로 안정적이나 HellaSwag에서 약세

---

## 3. KMMLU 결과

> **한국형 전문 지식 평가 (31개 카테고리)**

### 3.1 종합 성적

| 모델 | 정확도 | 정답 수 | 순위 |
|------|:------:|:-------:|:----:|
| **GPT-5.2** | **77.4%** | 3,776/4,880 | 1위 |
| GPT-OSS-20B | 65.9% | 2,384/3,617 | 2위 |
| Helpy-Pro | 55.0% | 2,639/4,795 | 3위 |

### 3.2 분야별 Top 5 (GPT-OSS-20B 기준)

| 순위 | 카테고리 | 정확도 |
|:----:|----------|:------:|
| 1 | **Math** | **97.8%** |
| 2 | Social-Welfare | 89.8% |
| 3 | Information-Technology | 89.7% |
| 4 | Electronics-Engineering | 88.3% |
| 5 | Marketing | 87.4% |

### 3.3 분야별 Bottom 3 (GPT-OSS-20B 기준)

| 순위 | 카테고리 | 정확도 |
|:----:|----------|:------:|
| 29 | Mechanical-Engineering | 57.8% |
| 30 | Materials-Engineering | 55.7% |
| 31 | **Taxation** | **46.7%** |

### 3.4 분석

- **GPT-5.2**: 모든 카테고리에서 최고 평균, 특히 법률/회계 분야 강점
- **GPT-OSS-20B**: 수학에서 97.8%로 압도적, IT/전자공학도 우수
- **Helpy-Pro**: 답변 형식 차이로 추출률에 영향

---

## 4. HAE-RAE Bench 결과

> **한국어 고유성 및 문화 이해 평가 (13개 태스크)**

### 4.1 종합 성적

| 모델 | 정확도 | 정답 수 | 순위 |
|------|:------:|:-------:|:----:|
| **GPT-5.2** | **70.5%** | 1,018/1,445 | 1위 |
| GPT-OSS-20B | 57.9% | 523/903 | 2위 |
| Helpy-Pro | 29.2% | 345/1,182 | 3위 |

### 4.2 태스크별 성능

| 태스크 | GPT-5.2 | GPT-OSS-20B | Helpy-Pro |
|--------|:-------:|:-----------:|:---------:|
| history (한국사) | **95.6%** | 54.3% | 62.5% |
| reading_comprehension | **86.2%** | 75.6% | 78.4% |
| rare_words (희귀어) | **90.6%** | 76.0% | 100%* |
| standard_nomenclature | **90.6%** | 82.8% | 66.7% |
| correct_definition | **87.8%** | 81.8% | - |
| loan_words (외래어) | 83.7% | **90.3%** | 100%* |
| csat_geo (수능 지리) | 80.7% | **85.4%** | 51.3% |
| csat_socio (수능 사회) | 76.5% | **76.8%** | 50.0% |
| general_knowledge | **73.4%** | 68.8% | 52.1% |
| csat_law (수능 법) | **66.3%** | 59.5% | 36.3% |
| date_understanding | 25.4% | 20.0% | 0.0% |

*샘플 수 적음 (1-5개)

### 4.3 분석

- **GPT-5.2**: 한국사(95.6%)에서 압도적 우위, 전반적으로 안정적
- **GPT-OSS-20B**: 외래어(90.3%), 수능 지리(85.4%)에서 GPT-5.2 능가
- **Helpy-Pro**: 추출률 저조 (장문 설명 후 정답 제시 패턴)

---

## 5. LogicKor 결과

> **한국어 논리적 사고력 평가 (LLM Judge 채점)**

### 5.1 채점 결과

| 모델 | 평균 점수 | 채점 수 | 5점 | 4점 | 3점 | 2점 | 1점 |
|------|:--------:|:-------:|:---:|:---:|:---:|:---:|:---:|
| **GPT-5.2** | **4.77/5** | 30 | 28 | 0 | 0 | 1 | 1 |
| Helpy-Pro | 4.10/5 | 42 | 21 | 11 | 5 | 3 | 2 |
| GPT-OSS-20B | 3.52/5 | 42 | 18 | 6 | 6 | 4 | 8 |

### 5.2 점수 분포 시각화

```
GPT-5.2      5점 ████████████████████████████  93%
             4점                               0%
             3점                               0%
             2점 █                             3%
             1점 █                             3%

Helpy-Pro    5점 ██████████████████████        50%
             4점 ███████████                   26%
             3점 █████                         12%
             2점 ███                            7%
             1점 ██                             5%

GPT-OSS-20B  5점 ██████████████████            43%
             4점 ██████                        14%
             3점 ██████                        14%
             2점 ████                          10%
             1점 ████████                      19%
```

### 5.3 분석

- **GPT-5.2**: 93%가 만점(5점), 논리력과 표현력 모두 탁월
- **Helpy-Pro**: 76%가 4점 이상, 안정적인 고품질 응답
- **GPT-OSS-20B**: 편차가 큼 (5점 43% vs 1점 19%)

---

## 6. 종합 분석

### 6.1 벤치마크별 1위

| 벤치마크 | 1위 | 점수 | 2위와 격차 |
|----------|-----|:----:|:----------:|
| KoBEST | GPT-5.2 | 93.5% | +7.7%p |
| KMMLU | GPT-5.2 | 77.4% | +11.5%p |
| HAE-RAE | GPT-5.2 | 70.5% | +12.6%p |
| LogicKor | GPT-5.2 | 4.77 | +0.67점 |

### 6.2 모델별 강약점

```
┌──────────────────────────────────────────────────────────────────┐
│ GPT-5.2                                                          │
│   강점: 전 영역 SOTA, 한국사(95.6%), LogicKor(4.77)              │
│   약점: API 비용                                                 │
│   추천: 고정밀 전문 서비스, 한국어 QA 시스템                     │
├──────────────────────────────────────────────────────────────────┤
│ Helpy-Pro                                                        │
│   강점: COPA(96.5%), BoolQ(100%), 논리력(4.10)                   │
│   약점: HAE-RAE 추출률 저조, HellaSwag(68.8%)                    │
│   추천: 교육/상담 챗봇, 기초 언어이해 서비스                     │
├──────────────────────────────────────────────────────────────────┤
│ GPT-OSS-20B                                                      │
│   강점: 수학(97.8%), 외래어(90.3%), 비용효율                     │
│   약점: LogicKor 편차(1점 19%), 역사(54.3%)                      │
│   추천: 수학 문제풀이, 범용 서비스, 온디바이스 AI                │
└──────────────────────────────────────────────────────────────────┘
```

### 6.3 사용 사례별 추천

| 사용 사례 | 1순위 | 2순위 | 이유 |
|----------|-------|-------|------|
| 전문 지식 QA | GPT-5.2 | GPT-OSS-20B | KMMLU 77.4% |
| 수학 문제 풀이 | **GPT-OSS-20B** | GPT-5.2 | Math 97.8% |
| 한국사/문화 | GPT-5.2 | Helpy-Pro | 역사 95.6% |
| 논리적 글쓰기 | GPT-5.2 | Helpy-Pro | LogicKor 4.77 |
| 교육/상담 | Helpy-Pro | GPT-5.2 | 안정적, 비용효율 |
| 예산 제한 | GPT-OSS-20B | Helpy-Pro | 오픈소스 |

---

## 7. 방법론

### 7.1 정답 추출

```python
# KMMLU, HAE-RAE (다중 선택)
patterns = [
    r'정답[은:\s]*\*?\*?([A-E])\*?\*?',
    r'정답[은:\s]*\*?\*?\(?([A-E])\)?',
]

# KoBEST COPA/HellaSwag (인덱스 변환)
model_answer = int(extracted) - 1  # 1-indexed → 0-indexed

# LogicKor (LLM Judge)
judge_model = "GPT-5.2"
score_scale = 1-5
```

### 7.2 제한사항

1. **샘플링**: 전체 데이터의 일부만 평가 (200개/태스크)
2. **추출 한계**: 모델별 답변 형식 차이로 일부 누락
3. **Helpy-Pro**: HAE-RAE에서 장문 설명 패턴으로 추출률 저조
4. **GPT-5.2 LogicKor**: 42개 중 30개만 유효 응답

---

## 8. 결론

### 핵심 결론

1. **GPT-5.2**가 한국어 4대 벤치마크 모두에서 1위 달성
2. **GPT-OSS-20B**는 수학(97.8%)에서 특출, 비용 대비 성능 우수
3. **Helpy-Pro**는 논리적 사고력(4.10/5)에서 GPT-OSS-20B(3.52) 대비 강점

### 향후 과제

- [ ] Helpy-Pro 답변 형식에 맞는 추출 로직 개선
- [ ] 전체 데이터셋 평가 (현재 샘플 200개)
- [ ] 추가 모델 평가 (Gemini 3 Pro/Flash 등)

---

## 문서 이력

| 버전 | 날짜 | 변경 사항 |
|------|------|----------|
| 1.0 | 2026-01-15 | 1차 평가 (부분 완료) |
| 2.0 | 2026-01-17 | Gemini 리서치 통합 |
| 3.0 | 2026-01-20 | 재평가 완료 (KMMLU, HAE-RAE) |
| **3.1** | **2026-01-21** | **LogicKor LLM Judge 채점 완료 (최종본)** |

---


*본 리포트는 2026년 1월 21일 기준 최종 작성되었습니다.*
